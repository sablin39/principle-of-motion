
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>
8.2 Linear Kalman Filtering</title>
<script language="JavaScript1.2" src="dui.js"></script>
<script language="JavaScript1.2" src="chaptertoc.js"></script>
<script type="text/JavaScript" language="JavaScript1.2" src="recommendMe.js"></script>
<!--[if lt IE 7.]>
<script defer type="text/javascript" src="/pngfix.js"></script>
<![endif]-->
<link rel="stylesheet" href="zapplication.css" type="text/css" />
<link rel="stylesheet" href="zshowkeywords.css" type="text/css" />
<link rel="stylesheet" type="text/css" href="ns.content.books24x7.css" />
</head>
<body leftmargin="20" topmargin="5" rightmargin="0" bgcolor="#FFFFFF">
<a href="#content" tabindex="1"><img src="images/_.gif" width="1" height="1" alt="Skip Navigation" title="Skip Navigation" border="0" /></a><div style="position:absolute;display:none;" id="thebubblediv"> <?xml version='1.0' encoding='utf-8'?><table id="bubbledown" border="0" cellpadding="0" cellspacing="0" xmlns:dc="http://purl.org/dc/elements/1.0/"><tr><td align="left" class="b24-bubbleoutside" background="images/di_legend_nw_d.gif" width="32" height="32"><img src="images/_.gif" alt="" border="0" height="32" width="32" /></td><td align="center" class="b24-bubbleoutside" background="images/di_legend_n_d.gif" width="165" height="32"><img src="images/_.gif" alt="" border="0" height="32" width="165" /></td><td align="right" class="b24-bubbleoutside" background="images/di_legend_ne_d.gif" width="32" height="32"><img src="images/_.gif" alt="" border="0" height="32" width="32" /></td></tr><tr><td class="b24-bubbleoutside" background="images/di_legend_w_d.gif" width="32" height="1"><img src="images/_.gif" alt="" border="0" height="1" width="32" /></td><td class="b24-boxcontent" bgcolor="#ffffff"><table border="0" cellpadding="0" cellspacing="5" width="195" id="bubbledownicons"><tr id="d0"><td colspan="2"><span class="b24-bubblelegendheader">Icon Legend</span></td></tr><tr valign="TOP" id="d1"><td><img width="16" height="16" border="0" src="images/i_bookreview.gif" /></td><td><span class="b24-bubblelegendtext">Content type is a review.</span></td></tr><tr valign="TOP" id="d2"><td><img width="16" height="16" border="0" src="images/i_summary.gif" /></td><td><span class="b24-bubblelegendtext">Content type is a summary.</span></td></tr><tr valign="TOP" id="d4"><td><img width="16" height="16" border="0" src="images/i_blueprint.gif" /></td><td><span class="b24-bubblelegendtext">Content type is an ExecBlueprint.</span></td></tr><tr valign="TOP" id="d8"><td><img width="16" height="16" border="0" src="images/i_reportb.gif" /></td><td><span class="b24-bubblelegendtext">Content type is a report.</span></td></tr><tr valign="TOP" id="d16"><td><img width="16" height="16" border="0" src="images/i_video.gif" /></td><td align="LEFT"><span class="b24-bubblelegendtext">Content type is video program.  Video programs are viewed using Adobe Flash 8 or newer.</span></td></tr><tr valign="TOP" id="d524288"><td><img width="16" height="16" border="0" src="images/i_recorded.gif" /></td><td align="LEFT"><span class="b24-bubblelegendtext">Content type is a recorded session</span></td></tr><tr valign="TOP" id="d1048576"><td><img width="16" height="16" border="0" src="images/i_journal_b.gif" /></td><td align="LEFT"><span class="b24-bubblelegendtext">Content type is a journal.</span></td></tr><tr valign="TOP" id="d2097152"><td><img width="16" height="16" border="0" src="images/i_newsletter.gif" /></td><td align="LEFT"><span class="b24-bubblelegendtext">Content type is a newsletter.</span></td></tr><tr valign="TOP" id="d32"><td><img width="16" height="16" border="0" src="images/i_companion.gif" /></td><td><span class="b24-bubblelegendtext">Includes companion files which can be downloaded by clicking on the links found at the bottom of the launch page for programs. </span></td></tr><tr valign="TOP" id="d64"><td><img width="16" height="16" border="0" src="images/i_book.gif" /></td><td><span class="b24-bubblelegendtext">Title is in personal folders</span></td></tr><tr valign="TOP" id="d128"><td><img width="16" height="16" border="0" src="images/i_notes.gif" /></td><td><span class="b24-bubblelegendtext">Contains a bookmark which can be found by clicking the link on the Table of Contents page. </span></td></tr><tr valign="TOP" id="d256"><td><img width="16" height="16" border="0" src="images/i_corporatenotes.gif" /></td><td><span class="b24-bubblelegendtext">Corporate Annotations</span></td></tr><tr valign="TOP" id="d2048"><td><img width="16" height="16" border="0" src="images/i_cdcontent.gif" /></td><td><span class="b24-bubblelegendtext">Includes supplemental CD content which can be downloaded by clicking the link found on the Table of Contents page</span></td></tr><tr valign="TOP" id="d4096"><td><img width="16" height="16" border="0" src="images/i_sound.gif" /></td><td><span class="b24-bubblelegendtext">Offers an audio MP3 file which can be retrieved by clicking the audio download tool. </span><img width="12" height="12" border="0" src="images/dui_tool_download.gif" /></td></tr><tr valign="TOP" id="d16384"><td><img width="16" height="16" border="0" src="images/i_lit.gif" /></td><td><span class="b24-bubblelegendtext">Offers a downloadable Microsoft Reader file which can be retrieved by clicking the download tool. </span><img width="12" height="12" border="0" src="images/dui_tool_download.gif" /></td></tr><tr valign="TOP" id="d32768"><td><img width="16" height="16" border="0" src="images/i_palm.gif" /></td><td><span class="b24-bubblelegendtext">Offers a downloadable Palm file which can be retrieved by clicking the download tool. </span><img width="12" height="12" border="0" src="images/dui_tool_download.gif" /></td></tr><tr valign="TOP" id="d8192"><td><img width="16" height="16" border="0" src="images/i_pdf.gif" /></td><td><span class="b24-bubblelegendtext">Offers a full text Adobe PDF which can be retrieved by clicking the download tool. </span><img width="12" height="12" border="0" src="images/dui_tool_download.gif" /></td></tr><tr valign="TOP" id="d65536"><td><img width="16" height="16" border="0" src="images/i_chapterpdf.gif" /></td><td><span class="b24-bubblelegendtext">Supports downloadable chapters which can only be downloaded by clicking the download tool when viewing a content page. </span><img width="12" height="12" border="0" src="images/dui_tool_download.gif" /></td></tr><tr valign="TOP" id="d131072"><td><img width="16" height="16" border="0" src="images/i_starchapterpdf.gif" /></td><td><span class="b24-bubblelegendtext">Includes Chapters to Go. These premium downloadable chapters are retrieved by clicking the download tool. </span><img width="12" height="12" border="0" src="images/dui_tool_download.gif" /></td></tr><tr valign="TOP" id="d16777216"><td><img width="16" height="16" border="0" src="images/i_ppt.gif" /></td><td><span class="b24-bubblelegendtext">Offers a downloadable Microsoft PowerPoint file which can be retrieved by clicking the download tool.</span><img width="12" height="12" border="0" src="images/dui_tool_download.gif" /></td></tr><tr valign="TOP" id="d262144"><td><img width="16" height="16" border="0" src="images/i_bookintopic.gif" /></td><td><span class="b24-bubblelegendtext">Title is in corporate topics</span></td></tr><tr valign="TOP" id="d4194304"><td><img width="16" height="16" border="0" src="images/i_checkmark_yes.gif" /></td><td><span class="b24-bubblelegendtext">I recommend this title.  If many users recommend this title a Yes! seal will appear on top left corner of the title graphic. </span><img width="26" height="27" border="0" src="images/best_reads_sm.seal.png" /></td></tr><tr valign="TOP" id="d8388608"><td><img width="16" height="16" border="0" src="images/i_checkmark_no.gif" /></td><td><span class="b24-bubblelegendtext">I do not recommend this title.</span></td></tr><tr valign="TOP" id="d33554432"><td><img width="16" height="16" border="0" src="images/i_mp4.gif" /></td><td><span class="b24-bubblelegendtext">Offers a MP4 video file which can be retrieved by clicking on the MP4 Video Download link in the Play Options box.</span></td></tr></table></td><td class="b24-bubbleoutside" background="images/di_legend_e_d.gif" width="32" height="1"><img src="images/_.gif" alt="" border="0" height="1" width="32" /></td></tr><tr><td class="b24-bubbleoutside" align="left" background="images/di_legend_sw_d.gif" width="32" height="70"><img src="images/_.gif" alt="" border="0" height="70" width="32" /></td><td class="b24-bubbleoutside" align="center" background="images/di_legend_s_d.gif" width="165" height="70"><img src="images/_.gif" alt="" border="0" height="70" width="165" /></td><td class="b24-bubbleoutside" align="right" background="images/di_legend_se_d.gif" width="32" height="70"><img src="images/_.gif" alt="" border="0" height="70" width="32" /></td></tr></table><table id="bubbleup" border="0" cellpadding="0" cellspacing="0" xmlns:dc="http://purl.org/dc/elements/1.0/"><tr><td align="LEFT" class="b24-bubbleoutside" background="images/di_legend_nw.gif" width="32" height="71" alt="" border="0"><img src="images/_.gif" alt="" border="0" height="71" width="32" /></td><td align="CENTER" class="b24-bubbleoutside" background="images/di_legend_n.gif" width="165" height="71" alt="" border="0"><img src="images/_.gif" alt="" border="0" height="71" width="165" /></td><td align="RIGHT" class="b24-bubbleoutside" background="images/di_legend_ne.gif" width="32" height="71" alt="" border="0"><img src="images/_.gif" alt="" border="0" height="71" width="32" /></td></tr><tr><td class="b24-bubbleoutside" background="images/di_legend_w.gif" width="32" height="1" alt="" border="0"><img src="images/_.gif" alt="" border="0" height="1" width="32" /></td><td class="b24-boxcontent" bgcolor="#ffffff"><table border="0" cellpadding="0" cellspacing="5" width="195" id="bubbleupicons"><tr id="u0"><td colspan="2"><span class="b24-bubblelegendheader">Icon Legend</span></td></tr><tr valign="TOP" id="u1"><td><img width="16" height="16" border="0" src="images/i_bookreview.gif" /></td><td><span class="b24-bubblelegendtext">Content type is a review.</span></td></tr><tr valign="TOP" id="u2"><td><img width="16" height="16" border="0" src="images/i_summary.gif" /></td><td><span class="b24-bubblelegendtext">Content type is a summary.</span></td></tr><tr valign="TOP" id="u4"><td><img width="16" height="16" border="0" src="images/i_blueprint.gif" /></td><td><span class="b24-bubblelegendtext">Content type is an ExecBlueprint.</span></td></tr><tr valign="TOP" id="u8"><td><img width="16" height="16" border="0" src="images/i_reportb.gif" /></td><td><span class="b24-bubblelegendtext">Content type is a report.</span></td></tr><tr valign="TOP" id="u16"><td><img width="16" height="16" border="0" src="images/i_video.gif" /></td><td align="LEFT"><span class="b24-bubblelegendtext">Content type is video program.  Video programs are viewed using Adobe Flash 8 or newer.</span></td></tr><tr valign="TOP" id="u524288"><td><img width="16" height="16" border="0" src="images/i_recorded.gif" /></td><td align="LEFT"><span class="b24-bubblelegendtext">Content type is a recorded session</span></td></tr><tr valign="TOP" id="u1048576"><td><img width="16" height="16" border="0" src="images/i_journal_b.gif" /></td><td align="LEFT"><span class="b24-bubblelegendtext">Content type is a journal.</span></td></tr><tr valign="TOP" id="u2097152"><td><img width="16" height="16" border="0" src="images/i_newsletter.gif" /></td><td align="LEFT"><span class="b24-bubblelegendtext">Content type is a newsletter.</span></td></tr><tr valign="TOP" id="u32"><td><img width="16" height="16" border="0" src="images/i_companion.gif" /></td><td><span class="b24-bubblelegendtext">Includes companion files which can be downloaded by clicking on the links found at the bottom of the launch page for programs. </span></td></tr><tr valign="TOP" id="u64"><td><img width="16" height="16" border="0" src="images/i_book.gif" /></td><td><span class="b24-bubblelegendtext">Title is in personal folders</span></td></tr><tr valign="TOP" id="u128"><td><img width="16" height="16" border="0" src="images/i_notes.gif" /></td><td><span class="b24-bubblelegendtext">Contains a bookmark which can be found by clicking the link on the Table of Contents page. </span></td></tr><tr valign="TOP" id="u256"><td><img width="16" height="16" border="0" src="images/i_corporatenotes.gif" /></td><td><span class="b24-bubblelegendtext">Corporate Annotations</span></td></tr><tr valign="TOP" id="u2048"><td><img width="16" height="16" border="0" src="images/i_cdcontent.gif" /></td><td><span class="b24-bubblelegendtext">Includes supplemental CD content which can be downloaded by clicking the link found on the Table of Contents page</span></td></tr><tr valign="TOP" id="u4096"><td><img width="16" height="16" border="0" src="images/i_sound.gif" /></td><td><span class="b24-bubblelegendtext">Offers an audio MP3 file which can be retrieved by clicking the audio download tool. </span><img width="12" height="12" border="0" src="images/dui_tool_download.gif" /></td></tr><tr valign="TOP" id="u16384"><td><img width="16" height="16" border="0" src="images/i_lit.gif" /></td><td><span class="b24-bubblelegendtext">Offers a downloadable Microsoft Reader file which can be retrieved by clicking the download tool. </span><img width="12" height="12" border="0" src="images/dui_tool_download.gif" /></td></tr><tr valign="TOP" id="u32768"><td><img width="16" height="16" border="0" src="images/i_palm.gif" /></td><td><span class="b24-bubblelegendtext">Offers a downloadable Palm file which can be retrieved by clicking the download tool. </span><img width="12" height="12" border="0" src="images/dui_tool_download.gif" /></td></tr><tr valign="TOP" id="u8192"><td><img width="16" height="16" border="0" src="images/i_pdf.gif" /></td><td><span class="b24-bubblelegendtext">Offers a full text Adobe PDF which can be retrieved by clicking the download tool. </span><img width="12" height="12" border="0" src="images/dui_tool_download.gif" /></td></tr><tr valign="TOP" id="u65536"><td><img width="16" height="16" border="0" src="images/i_chapterpdf.gif" /></td><td><span class="b24-bubblelegendtext">Supports downloadable chapters which can only be downloaded by clicking the download tool when viewing a content page. </span><img width="12" height="12" border="0" src="images/dui_tool_download.gif" /></td></tr><tr valign="TOP" id="u131072"><td><img width="16" height="16" border="0" src="images/i_starchapterpdf.gif" /></td><td><span class="b24-bubblelegendtext">Includes Chapters to Go. These premium downloadable chapters are retrieved by clicking the download tool. </span><img width="12" height="12" border="0" src="images/dui_tool_download.gif" /></td></tr><tr valign="TOP" id="u16777216"><td><img width="16" height="16" border="0" src="images/i_ppt.gif" /></td><td><span class="b24-bubblelegendtext">Offers a downloadable Microsoft PowerPoint file which can be retrieved by clicking the download tool.</span><img width="12" height="12" border="0" src="images/dui_tool_download.gif" /></td></tr><tr valign="TOP" id="u262144"><td><img width="16" height="16" border="0" src="images/i_bookintopic.gif" /></td><td><span class="b24-bubblelegendtext">Title is in corporate topics</span></td></tr><tr valign="TOP" id="u4194304"><td><img width="16" height="16" border="0" src="images/i_checkmark_yes.gif" /></td><td><span class="b24-bubblelegendtext">I recommend this title.  If many users recommend this title a Yes! seal will appear on top left corner of the title graphic. </span><img width="26" height="27" border="0" src="images/best_reads_sm.seal.png" /></td></tr><tr valign="TOP" id="u8388608"><td><img width="16" height="16" border="0" src="images/i_checkmark_no.gif" /></td><td><span class="b24-bubblelegendtext">I do not recommend this title.</span></td></tr><tr valign="TOP" id="u33554432"><td><img width="16" height="16" border="0" src="images/i_mp4.gif" /></td><td><span class="b24-bubblelegendtext">Offers a MP4 video file which can be retrieved by clicking on the MP4 Video Download link in the Play Options box.</span></td></tr></table></td><td class="b24-bubbleoutside" background="images/di_legend_e.gif" width="32" height="1"><img src="images/_.gif" alt="" border="0" height="1" width="32" /></td></tr><tr><td class="b24-bubbleoutside" align="LEFT" background="images/di_legend_sw.gif" width="32" height="32" alt="" border="0"><img src="images/_.gif" alt="" border="0" height="32" width="32" /></td><td class="b24-bubbleoutside" align="CENTER" background="images/di_legend_s.gif" width="165" height="32" alt="" border="0"><img src="images/_.gif" alt="" border="0" height="32" width="165" /></td><td class="b24-bubbleoutside" align="RIGHT" background="images/di_legend_se.gif" width="32" height="32" alt="" border="0"><img src="images/_.gif" alt="" border="0" height="32" width="32" /></td></tr></table> </div> <div id="overlay" class="b24-download_overlay" onclick="javascript:SunDown();"></div> <div id="download" class="b24-download_bubble"></div> <?xml version='1.0' encoding='utf-8'?><span id="b24-booktype-10749" style="display:none" xmlns:dc="http://purl.org/dc/elements/1.0/">0</span><div class="b24-bookmeta" xmlns:dc="http://purl.org/dc/elements/1.0/"><table border="0" cellpadding="0" cellspacing="2" class="b24-folderbook1"><tr><td valign="TOP" align="LEFT" height="109" width="98"><a border="0" href="1.html"><div><img border="0" align="Left" id="COVERIMAGE10749" src="0262033275.gif" height="99" width="88" alt="The Coverimage" title="The Coverimage" /></div><br /></a></td><td width="2" valign="TOP" height="109"></td><td valign="Top" align="Left"><table border="0" cellpadding="0" cellspacing="4" width="100%" height="109"><tr><td valign="TOP" align="Left" nowrap="1" colspan="2"><a border="0"><span id="b24-chaptertitle" class="b24-bookchaptertitle">Chapter 8 - 
 Kalman Filtering</span></a></td></tr><tr><td valign="Top" align="Left" colspan="2"><span id="b24-booktitle-10749">Principles of Robot Motion: Theory, Algorithms, and Implementation</span></td></tr><tr><td valign="TOP" align="Left" colspan="2"><span id="b24-bookauthor-10749" class="b24-bookauthor">by <a class="b24-bookauthor">Howie Choset</a> et al.</span> </td></tr><tr><td valign="TOP" align="Left" colspan="2"><a><span id="b24-bookimprint-10749" class="b24-bookimprint">The MIT Press</span></a><span id="b24-bookrights-10749" class="b24-bookcwdate"> © 2005</span> </td></tr><tr><td valign="TOP" align="Left" colspan="2" id="ID10749"></td></tr><tr><td colspan="2" valign="TOP" align="LEFT"></td></tr></table></td></tr><tr><td valign="TOP" align="Center" colspan="3" height="10"><img src="images/_.gif" width="1" border="0" alt="" height="10" /></td></tr></table></div>
<script language="JavaScript">
<!--
function Next(item) {
var cm = new Array(1,48,25,99,25,66,34,71,6,60,82,23,2,17,81)
var a1 = new Array(0,12,8)
var a2 = new Array(14,1,7)
var a3 = new Array(6,13,9)
var a4 = new Array(3,4,10)
var a5 = new Array(2,11,5)
var b1="00"+cm[a1[item]]; b1= b1.substr(b1.length-2,2)
var b2="00"+cm[a2[item]]; b2= b2.substr(b2.length-2,2)
var b3="00"+cm[a3[item]]; b3= b3.substr(b3.length-2,2)
var b4="00"+cm[a4[item]]; b4= b4.substr(b4.length-2,2)
var b5="00"+cm[a5[item]]; b5= b5.substr(b5.length-2,2)
var h ='viewer.asp?bookid=10749\46chunkid='+b1+b2+b3+b4+b5;
this.location=h}
//  -->
</script>
<?xml version='1.0' encoding='utf-8'?><table cellspacing="0" cellpadding="0" border="0" width="100%"><tr><td align="Center"><table cellspacing="5" cellpadding="0" border="0" width="85%"></table></td></tr><tr><td bgcolor="#000000"><img src="images/transdot.gif" width="1" height="1" border="0" alt="" /></td></tr></table><table border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td colspan="3" height="5"><img src="images/_.gif" width="1" alt="" border="0" height="5" /></td>
</tr>
<tr>
<td class="b24-chunknavigate" width="25%" align="left"><a border="0" accesskey="P" href="49.html"><img src="images/arrow_readprevious.gif" width="94" height="22" hspace="0" alt="Previous Section" title="Previous Section" border="0" /></a></td>
<td class="b24-chunknavigate" width="75%" align="center">
<table cellpadding="0" cellspacing="0" border="0">
</table>
</td>
<td class="b24-chunknavigate" width="25%" align="right"><a border="0" href="viewer.asp?bookid=10749&amp;chunkid=671608266"><img width="1" height="1" hspace="1" border="0" alt="" src="images/_.gif" /></a><a border="0" accesskey="N" href="51.html"><img src="images/arrow_readnext.gif" width="94" height="22" hspace="0" alt="Next Section" title="Next Section" border="0" /></a></td>
</tr>
<tr>
<td colspan="3" height="5"><img src="images/_.gif" width="1" alt="" border="0" height="5" /></td>
</tr>
</table>
<div class="chapter">
<a name="ch08"></a>
<div class="section">
<h2 class="first-section-title">
<a name="684"></a><a name="ch08lev1sec2"></a><span class="section-titlelabel">8.2 </span>Linear Kalman Filtering</h2>
<p class="first-para">One reason that Kalman filtering has become such a popular estimation method is that it is extremely easy to implement for linear systems. The equations in <a class="internaljump" href="#ch08lev2sec5">section 8.2.5</a> can be implemented directly with little understanding of the underlying theory. This feature makes Kalman filtering useful and accessible to a broad range of potential users, but it does not mean that the underlying theory is unimportant. In fact, most modern applications of Kalman filtering employ substantial modifications of the original equations. For example, modifications are necessary to address nonlinear sensor models or non-Gaussian noise models in robot localization and mapping problems. Other modifications are often used to reduce computational complexity.</p>
<p class="para">This section is intended to provide the reader with an understanding of the fundamentals of Kalman filtering for linear systems. The approach taken here is intuitive and uses basic facts from geometry and linear algebra to reconstruct Kalman's equations. Some knowledge of multivariate Gaussian distributions is assumed (see the statistics primer in <a href="98.html" class="chapterjump">appendix I</a> for an overview). We begin with a simplified version <a name="685"></a><a name="page273"></a>of the Kalman filtering problem to illustrate the basic concept, then we incrementally add complexity until we arrive at the full Kalman equations. An example illustrating the application of the Kalman filter equations is presented, and the property of observability in linear systems is introduced. With the understanding provided here, the reader should be able to modify the Kalman filter to fit the needs of a specific estimation problem.</p>
<div class="section">
<h3 class="sect3-title">
<a name="686"></a><a name="ch08lev2sec1"></a><span class="section-titlelabel">8.2.1 </span>Overview</h3>
<p class="first-para">In order to apply Kalman filtering to the problem of robot localization, it is necessary to define equations that can be used to model the dynamics and sensors of the robot system. The vector <i class="emphasis">x</i> is used to denote the system (robot) state as it evolves through time. This chapter uses discrete time models, meaning that the continuously varying robot state is sampled at discrete, regularly spaced intervals of time to create the sequence <i class="emphasis">x</i>(<i class="emphasis">k</i>), <i class="emphasis">k</i> ?{0, 1, 2, ...}. Specifically, if <i class="emphasis">x</i>(0) is the value of the state at time <i class="emphasis">t</i> = <i class="emphasis">t</i><sub>0</sub>, then <i class="emphasis">x</i>(<i class="emphasis">k</i>) is the value of the state at time <i class="emphasis">t</i><sub>0</sub> + <i class="emphasis">Tk</i>, where <i class="emphasis">T</i> is defined to be the sampling time step.</p>
<p class="para">For now we assume that the evolution of the robot state and the values measured by the robot sensors can be modeled as a linear dynamical discrete-time system:</p>
<div class="equation" mathml="yes">
<a name="687"></a><a name="ch08eqn01"></a>
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.1) </span></td><td valign="top"><img src="figu273_1.jpg" /><br /></td>
</tr>
</table>
</div>
<div class="equation" mathml="yes">
<a name="688"></a><a name="ch08eqn02"></a>
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.2) </span></td><td valign="top"><img src="figu273_2.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">The vector <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1048" src="figu273_3.jpg" height="18" width="84" title="" border="0" /></span></span> denotes the full system state. The vector <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1049" src="figu273_4.jpg" height="18" width="86" title="" border="0" /></span></span> is used to represent the system input such as velocity commands, torques, or forces intentionally applied to the robot. The vector <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1050" src="figu273_5.jpg" height="19" width="85" title="" border="0" /></span></span> is the system output and contains the values reported by the system sensors. The matrix <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1051" src="figu273_6.jpg" height="18" width="105" title="" border="0" /></span></span> encodes the dynamics of the system, and <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1052" src="figu273_7.jpg" height="18" width="112" title="" border="0" /></span></span> describes how the inputs drive the dynamics. The vector <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1053" src="figu273_8.jpg" height="18" width="82" title="" border="0" /></span></span> is called the <i class="emphasis">process noise</i> and is assumed to be white Gaussian noise with zero mean and covariance matrix <i class="emphasis">V</i> (<i class="emphasis">k</i>).<sup>[<a name="ch08fnt08_1" href="#ftn.ch08fnt08_1">1</a>]</sup> The process noise is used to account for unmodeled disturbances (such as slipping wheels) that affect the system dynamics. The matrix <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1054" src="figu273_9.jpg" height="18" width="111" title="" border="0" /></span></span> describes how state vectors are mapped into outputs. The <i class="emphasis">measurement noise</i> vector <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1055" src="figu273_10.jpg" height="18" width="94" title="" border="0" /></span></span> is assumed to be white Gaussian noise with zero mean and covariance matrix <i class="emphasis">W</i> (<i class="emphasis">k</i>). Here we assume that <i class="emphasis">H</i>(<i class="emphasis">k</i>) is full row rank for all <i class="emphasis">k</i>, although it may not be square.</p>
<p class="para">
<a name="690"></a><a name="IDX-274"></a>The objective of Kalman filtering is to determine the "best" estimate of the state <i class="emphasis">x</i> at the <i class="emphasis">k</i>th time step given a previous estimate together with the known input <i class="emphasis">u</i>(<i class="emphasis">k</i>) and output <i class="emphasis">y</i>(<i class="emphasis">k</i>). In order to achieve this there are two separate difficulties that must be overcome. The first is the presence of the unknown and unmeasurable noise vectors <i class="emphasis">v</i>(<i class="emphasis">k</i>) and <i class="emphasis">w</i>(<i class="emphasis">k</i>). Hence, as its name implies, one task of the Kalman filter is to filter out these unwanted disturbances. The second difficulty is that the state in general cannot be directly observed from the outputs because <i class="emphasis">H</i>(<i class="emphasis">k</i>) may not be invertible. This means that the state estimate must be reconstructed using the time history of the known signals <i class="emphasis">y</i>(<i class="emphasis">k</i>) and <i class="emphasis">u</i>(<i class="emphasis">k</i>) together with known parameters <i class="emphasis">F</i>(<i class="emphasis">k</i>), <i class="emphasis">G</i>(<i class="emphasis">k</i>), <i class="emphasis">H</i>(<i class="emphasis">k</i>), <i class="emphasis">V</i> (<i class="emphasis">k</i>), and <i class="emphasis">W</i> (<i class="emphasis">k</i>).<sup>[<a name="ch08fnt08_2" href="#ftn.ch08fnt08_2">2</a>]</sup> A device that does this is called an observer. The Kalman filter is both an observer and a filter.</p>
<p class="last-para">In this section we build up to Kalman's equations by first building an observer for a system with no measurement noise. Specifically, we derive the equations for a simple two-step observer using only a few simple facts from linear algebra. We then introduce the concept of using a multivariate Gaussian distribution as a state estimate, and we rederive the simple observer equations that use this kind of estimate. This leads naturally to the derivation of the Kalman filter equations for linear discrete time systems.</p>
</div>
<div class="section">
<h3 class="sect3-title">
<a name="692"></a><a name="ch08lev2sec2"></a><span class="section-titlelabel">8.2.2 </span>A Simple Observer</h3>
<p class="first-para">Here we consider a linear discrete time system with no noise:</p>
<div class="equation" mathml="yes">
<a name="693"></a><a name="ch08eqn03"></a>
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.3) </span></td><td valign="top"><img src="figu274_1.jpg" /><br /></td>
</tr>
</table>
</div>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.4) </span></td><td valign="top"><img src="figu274_2.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">Here, <i class="emphasis">H</i>(<i class="emphasis">k</i>) is assumed to be full row rank at every <i class="emphasis">k</i>. The objective is to build an observer for this system, i.e., we would like to find a set of equations that allows us to reconstruct the state <i class="emphasis">x</i>. The observer we build will be recursive<sup>[<a name="ch08fnt08_3" href="#ftn.ch08fnt08_3">3</a>]</sup>: it will take the most recent estimate together with the most recent input <i class="emphasis">u</i> and output <i class="emphasis">y</i>, and then return the next estimate. If the observer works (and the assumptions are valid), then the estimate will converge to the actual value of <i class="emphasis">x</i> over time.</p>
<p class="para">Before we begin deriving the necessary equations, we first introduce some notation to make the job of keeping track of the estimate easier. Given two integers <i class="emphasis">k</i><sub>1</sub> and <i class="emphasis">k</i><sub>2</sub> <a name="695"></a><a name="page275"></a>with <i class="emphasis">k</i><sub>1</sub> <span class="unicode">&#8805;</span> <i class="emphasis">k</i><sup>2</sup>, we use <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1058" src="figu275_1.jpg" height="18" width="74" title="" border="0" /></span></span> to denote the value of the state estimate at time <i class="emphasis">k</i><sub>1</sub> given the value of the output at all times up to <i class="emphasis">k</i><sub>2</sub>. The symbol <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1059" src="figu275_2.jpg" height="18" width="74" title="" border="0" /></span></span> is pronounced "<i class="emphasis">x</i> hat at <i class="emphasis">k</i>-one given <i class="emphasis">k</i>-two." This notation may seem cumbersome at first, but its usefulness will soon become apparent.</p>
<p class="para">Now the observer follows an intuitive two-step process. Given the current state estimate <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1060" src="figu275_3.jpg" height="18" width="63" title="" border="0" /></span></span>, we first generate a prediction <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1061" src="figu275_4.jpg" height="19" width="95" title="" border="0" /></span></span> by propagating the prior estimate according to the system dynamics in <a class="internaljump" href="#ch08eqn03">equation (8.3)</a>. We then correct the prediction based on the output <i class="emphasis">y</i>(<i class="emphasis">k</i> + 1) to generate the next estimate <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1062" src="figu275_5.jpg" height="19" width="125" title="" border="0" /></span></span>. We call these two steps the prediction and update steps, respectively.</p>
<p class="para">For the prediction step, we simply substitute <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1063" src="figu275_6.jpg" height="18" width="63" title="" border="0" /></span></span> into <a class="internaljump" href="#ch08eqn03">equation (8.3)</a> to get</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.5) </span></td><td valign="top"><img src="figu275_7.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">To perform the update, we first note that given the output <i class="emphasis">y</i>(<i class="emphasis">k</i> + 1), the system state is constrained to lie on the hyperplane</p>
<div class="informalequation" mathml="yes">
<img src="figu275_8.jpg" /><br />
</div>
<p class="para">Note that <span class="unicode">&#937;</span> is the set of states that are consistent with the measurement <i class="emphasis">y</i>(<i class="emphasis">k</i> + 1). For our simple observer, we choose the next estimate <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1066" src="figu275_9.jpg" height="18" width="126" title="" border="0" /></span></span> to be the point in <span class="unicode">&#937;</span> that has the shortest distance to the prediction <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1067" src="figu275_10.jpg" height="18" width="92" title="" border="0" /></span></span>. This is an intuitive choice: we have some reason to believe that <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1068" src="figu275_11.jpg" height="18" width="93" title="" border="0" /></span></span> is close to the actual state value, and we know that the actual state must be in <span class="unicode">&#937;</span>. So it makes sense to choose the update to be the point in <span class="unicode">&#937;</span> that is closest to <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1069" src="figu275_12.jpg" height="18" width="99" title="" border="0" /></span></span>. This choice of update is depicted graphically in <a class="internaljump" href="#ch08fig02">figure 8.2</a>. We can use algebra to find an expression for <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1070" src="figu275_13.jpg" height="18" width="122" title="" border="0" /></span></span>. Define the vector <span class="unicode">&#916;</span><i class="emphasis">x</i> to be the vector that points from <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1071" src="figu275_14.jpg" height="19" width="87" title="" border="0" /></span></span> to <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1072" src="figu275_15.jpg" height="19" width="117" title="" border="0" /></span></span>, i.e.,</p>
<div class="informalequation" mathml="yes">
<img src="figu275_16.jpg" /><br />
</div>
<div class="figure">
<a name="696"></a><a name="ch08fig02"></a><span class="figuremediaobject"><a href="javascript:PopImage('IMG_1074','fig8-2_0.jpg','907','452')" name="IMG_1074" target="_self"><img alt="Image from book" id="IMG_1074" src="fig8-2.jpg" height="174" width="350" title="Click To expand" border="0" /></a></span>
<br style="line-height: 1" />
<span class="figure-title"><span class="figure-titlelabel">Figure 8.2: </span>The set <span class="unicode">&#937;</span> corresponds to the states consistent with the current output <i class="emphasis">y</i>(<i class="emphasis">k</i> + 1). The corrected state lies in this set and is the state closest to the predicted estimate.</span>
</div>
<p class="para">
<a name="697"></a><a name="page276"></a>By our choice of <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1075" src="figu276_1.jpg" height="18" width="119" title="" border="0" /></span></span>, <span class="unicode">&#916;</span><i class="emphasis">x</i> is the shortest vector pointing from <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1076" src="figu276_2.jpg" height="18" width="89" title="" border="0" /></span></span> to <span class="unicode">&#937;</span>. This means that <span class="unicode">&#916;</span><i class="emphasis">x</i> must be <i class="emphasis">orthogonal</i> to <span class="unicode">&#937;</span> by the standard inner product on <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1077" src="figu276_3.jpg" height="15" width="22" title="" border="0" /></span></span>, i.e., we must have <i class="emphasis">a<sup>T</sup></i> <span class="unicode">&#916;</span><i class="emphasis">x</i> = 0 for any <i class="emphasis">a</i> that is parallel to <span class="unicode">&#937;</span>.<sup>[<a name="ch08fnt08_4" href="#ftn.ch08fnt08_4">4</a>]</sup> Now we need two basic facts from linear algebra [398]:</p>
<ol class="orderedlist">
<li class="first-listitem">
<p class="first-para">A vector <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1078" src="figu276_4.jpg" height="15" width="57" title="" border="0" /></span></span> is parallel to <span class="unicode">&#937;</span> if and only if <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1)<i class="emphasis">a</i> = 0. The set of all such <i class="emphasis">a</i> is called the <i class="emphasis">null space</i> of <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1) and is denoted by null(<i class="emphasis">H</i>(<i class="emphasis">k</i> + 1)).</p>
</li>
<li class="listitem">
<p class="first-para">A vector <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1079" src="figu276_5.jpg" height="15" width="64" title="" border="0" /></span></span> is orthogonal to every vector in the space null(<i class="emphasis">H</i>(<i class="emphasis">k</i> + 1)) if and only if <i class="emphasis">b</i> is in the <i class="emphasis">column space</i> of <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1)<sup><i class="emphasis">T</i></sup>, where the column space of <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1) is denoted column(<i class="emphasis">H</i>(<i class="emphasis">k</i> + 1)<sup><i class="emphasis">T</i></sup>) and is defined to be the span of the columns of <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1)<sup><i class="emphasis">T</i></sup>.</p>
</li>
</ol>
<p class="para">Note that any vector <i class="emphasis">b</i> <span class="unicode">&#8714;</span> column(<i class="emphasis">H</i>(<i class="emphasis">k</i> + 1)<sup><i class="emphasis">T</i></sup>) can be written as a weighted sum of the columns of <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1)<sup><i class="emphasis">T</i></sup>, which is equivalent to saying that <i class="emphasis">b</i> = <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1)<sup><i class="emphasis">T</i></sup> <span class="unicode">&#947;</span> for some <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1080" src="figu276_6.jpg" height="19" width="60" title="" border="0" /></span></span>. Combining these two facts, we see that in order to have <span class="unicode">&#916;</span><i class="emphasis">x</i> orthogonal to <span class="unicode">&#937;</span>, we must have</p>
<div class="informalequation" mathml="yes">
<img src="figu276_7.jpg" /><br />
</div>
<p class="para">for some vector <span class="unicode">&#947;</span> in <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1082" src="figu276_8.jpg" height="15" width="23" title="" border="0" /></span></span>. Next, we will try to find <span class="unicode">&#947;</span>.</p>
<p class="para">Define the <i class="emphasis">innovation error</i> <span class="unicode">&#957;</span> to be the difference between the actual output <i class="emphasis">y</i>(<i class="emphasis">k</i> +1) and the predicted output <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1083" src="figu276_9.jpg" height="18" width="179" title="" border="0" /></span></span>. In other words, <span class="unicode">&#957;</span> is the difference between what the sensors reported and what they would have reported if the prediction was correct. The larger the discrepancy between the actual and predicted measurements, the larger the necessary correction <span class="unicode">&#916;</span><i class="emphasis">x</i> will be. So for now we make the guess that <span class="unicode">&#947;</span> can be written as a linear function of <span class="unicode">&#957;</span>, i.e., <span class="unicode">&#947;</span> = <i class="emphasis">K</i> <span class="unicode">&#957;</span> for some <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1084" src="figu276_10.jpg" height="15" width="84" title="" border="0" /></span></span>. This yields the equation</p>
<div class="informalequation" mathml="yes">
<img src="figu276_11.jpg" /><br />
</div>
<p class="para">If we can find a <i class="emphasis">K</i> such that <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1086" src="figu276_12.jpg" height="19" width="238" title="" border="0" /></span></span> agrees with the measurement <i class="emphasis">y</i>(<i class="emphasis">k</i> + 1) (i.e., <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1087" src="figu276_13.jpg" height="19" width="220" title="" border="0" /></span></span>, then our guess is correct and we have an expression for <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1088" src="figu276_14.jpg" height="19" width="131" title="" border="0" /></span></span>. To find <i class="emphasis">K</i>, we start with the requirement that</p>
<div class="equation" mathml="yes">
<a name="699"></a><a name="ch08eqn06"></a>
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.6) </span></td><td valign="top"><img src="figu276_15.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">which implies that</p>
<div class="informalequation" mathml="yes">
<img src="figu276_16.jpg" /><br />
</div>
<p class="para">
<a name="700"></a><a name="page277"></a>Substituting <span class="unicode">&#916;</span><i class="emphasis">x</i> = <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1)<sup><i class="emphasis">T</i></sup> <i class="emphasis">K</i> <span class="unicode">&#957;</span> yields</p>
<div class="equation" mathml="yes">
<a name="701"></a><a name="ch08eqn07"></a>
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.7) </span></td><td valign="top"><img src="figu277_1.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">which implies that <i class="emphasis">K</i> = (<i class="emphasis">H</i>(<i class="emphasis">k</i> + 1)<i class="emphasis">H</i>(<i class="emphasis">k</i> + 1)<sup><i class="emphasis">T</i></sup>)<sup>&#8722;1</sup>. Note that the matrix <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1) <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1)<sup><i class="emphasis">T</i></sup> is guaranteed to be invertible by the assumption that <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1) is full row rank for all <i class="emphasis">k</i>. We were able to find a <i class="emphasis">K</i> that solves <a class="internaljump" href="#ch08eqn07">equation (8.7)</a> meaning that for the choice <span class="unicode">&#916;</span><i class="emphasis">x</i> = <i class="emphasis">K</i> <span class="unicode">&#957;</span>, <a class="internaljump" href="#ch08eqn06">equation (8.6)</a> is satisfied. Our guess that <span class="unicode">&#916;</span><i class="emphasis">x</i> is a linear function of <span class="unicode">&#957;</span> is then verified. As a result, we now have equations that fully express our simple two-step observer:</p>
<p class="para">
<b class="bold"><i class="emphasis">prediction:</i></b>
</p>
<div class="informalequation" mathml="yes">
<img src="figu277_2.jpg" /><br />
</div>
<p class="para">
<b class="bold"><i class="emphasis">update:</i></b>
</p>
<div class="informalequation" mathml="yes">
<img src="figu277_3.jpg" /><br />
</div>
<p class="para">Note that in the update equation we have denoted <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1) simply by <i class="emphasis">H</i> to keep the expression manageable.</p>
<p class="last-para">It turns out that there are some problems with this observer. Our choice of the update is naive. Since the update is always perpendicular to the set <span class="unicode">&#937;</span>, only the component of the state that directly affects the current sensor reading is updated. Estimate errors in the direction parallel to <span class="unicode">&#937;</span> are never corrected. As a result, the estimate <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1094" src="figu277_4.jpg" height="18" width="12" title="" border="0" /></span></span> will not in general converge to <i class="emphasis">x</i>. However, what is important is that the intuitive notions of prediction and correction are the same as those used in the Kalman filter. In the following discussion we follow this intuition toward Kalman's equations, and in the process we fix the problems associated with our simple observer.</p>
</div>
<div class="section">
<h3 class="sect3-title">
<a name="702"></a><a name="ch08lev2sec3"></a><span class="section-titlelabel">8.2.3 </span>Observing with Probability Distributions</h3>
<p class="first-para">The estimate produced by the simple observer discussed in the <a class="internaljump" href="#ch08lev2sec2">previous section</a> is a vector. In contrast, the estimate produced by a Kalman filter is a multivariate Gaussian probability distribution over the state space. In addition to providing a vector estimate <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1095" src="figu277_5.jpg" height="18" width="63" title="" border="0" /></span></span>, a Kalman filter also provides an estimate of the error covariance <i class="emphasis">P</i>(<i class="emphasis">k</i> | <i class="emphasis">k</i>) associated with <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1096" src="figu277_6.jpg" height="18" width="63" title="" border="0" /></span></span>. In this section, we advance the simple observer from the <a class="internaljump" href="#ch08lev2sec2">previous section</a> one step toward Kalman's filter by augmenting it to provide a covariance estimate.</p>
<p class="para">First we review some basic facts about multivariate Gaussian distributions. A more detailed discussion can be found in the statistics primer in <a href="98.html" class="chapterjump">appendix I</a>. For <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1097" src="figu277_7.jpg" height="15" width="58" title="" border="0" /></span></span>, a <a name="703"></a><a name="page278"></a>multivariate Gaussian distribution has a PDF of the form</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.8) </span></td><td valign="top"><img src="figu278_1.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">where <i class="emphasis">x</i> is a vector in <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1099" src="figu278_2.jpg" height="13" width="19" title="" border="0" /></span></span> and <i class="emphasis">P</i> is a symmetric, positive definite <i class="emphasis">n</i> × <i class="emphasis">n</i> matrix. It is clear that <i class="emphasis">p</i>(<i class="emphasis">x</i>) is entirely defined by <i class="emphasis">x</i> and <i class="emphasis">P</i>. Further, <i class="emphasis">E</i>[<i class="emphasis">x</i>] = <i class="emphasis">x</i> and <i class="emphasis">E</i>[(<i class="emphasis">x</i> <span class="unicode">&#8722;</span> <i class="emphasis">x</i>)(<i class="emphasis">x</i> <span class="unicode">&#8722;</span> <i class="emphasis">x</i>)<sup><i class="emphasis">T</i></sup>] = <i class="emphasis">P</i>, so <i class="emphasis">x</i> and <i class="emphasis">P</i> are called the <i class="emphasis">mean vector</i> and <i class="emphasis">covariance matrix</i>, respectively. In the Kalman filter, we maintain a state estimate which will be the mean of a Gaussian distribution, so in the sequel we replace <i class="emphasis">x</i> with <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1100" src="figu278_3.jpg" height="15" width="10" title="" border="0" /></span></span>.</p>
<p class="para">In this section, we consider linear discrete time systems with process noise but no measurement noise, i.e.,</p>
<div class="equation" mathml="yes">
<a name="704"></a><a name="ch08eqn09"></a>
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.9) </span></td><td valign="top"><img src="figu278_4.jpg" /><br /></td>
</tr>
</table>
</div>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.10) </span></td><td valign="top"><img src="figu278_5.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">As before, <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1103" src="figu278_6.jpg" height="18" width="77" title="" border="0" /></span></span> is assumed to be white noise chosen from a zero-mean Gaussian distribution with covariance matrix <i class="emphasis">V</i>(<i class="emphasis">k</i>) and the matrix <i class="emphasis">H</i>(<i class="emphasis">k</i>) is assumed to be full row rank for all <i class="emphasis">k</i>.</p>
<p class="para">Here we follow the same basic steps of prediction and update that were used for the simple observer. The main difference is that this time we must generate both a state vector estimate <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1104" src="figu278_7.jpg" height="18" width="63" title="" border="0" /></span></span> and a covariance matrix estimate <i class="emphasis">P</i>(<i class="emphasis">k</i> | <i class="emphasis">k</i>). Hence the prediction step will generate <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1105" src="figu278_8.jpg" height="18" width="99" title="" border="0" /></span></span> and <i class="emphasis">P</i>(<i class="emphasis">k</i> + 1 | <i class="emphasis">k</i>), and the update step will generate the next estimate given by <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1106" src="figu278_9.jpg" height="18" width="138" title="" border="0" /></span></span> and <i class="emphasis">P</i>(<i class="emphasis">k</i> + 1 | <i class="emphasis">k</i> + 1).</p>
<p class="para">The state vector prediction <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1107" src="figu278_10.jpg" height="18" width="96" title="" border="0" /></span></span> is found by substituting <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1108" src="figu278_11.jpg" height="18" width="63" title="" border="0" /></span></span> into <a class="internaljump" href="#ch08eqn09">equation (8.9)</a>. Since the expected value of <i class="emphasis">v</i>(<i class="emphasis">k</i>) is zero, the resulting prediction is</p>
<div class="equation" mathml="yes">
<a name="705"></a><a name="ch08eqn11"></a>
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.11) </span></td><td valign="top"><img src="figu278_12.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">To compute the predicted covariance matrix we start with the definition of the covariance matrix:</p>
<div class="informalequation" mathml="yes">
<img src="figu278_13.jpg" /><br />
</div>
<p class="para">Substituting <i class="emphasis">x</i>(<i class="emphasis">k</i> + 1) from <a class="internaljump" href="#ch08eqn09">equation (8.9)</a> and <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1111" src="figu278_14.jpg" height="19" width="95" title="" border="0" /></span></span> from <a class="internaljump" href="#ch08eqn11">equation (8.11)</a>, then multiplying the terms inside the expectation, yields</p>
<div class="informalequation" mathml="yes">
<img src="figu278_15.jpg" /><br />
</div>
<p class="para">The fact that <i class="emphasis">v</i>(<i class="emphasis">k</i>) is independent of both <i class="emphasis">x</i>(<i class="emphasis">k</i>) and <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1113" src="figu278_16.jpg" height="16" width="51" title="" border="0" /></span></span> implies that <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1114" src="figu278_17.jpg" height="16" width="400" title="" border="0" /></span></span>, which is zero due to the fact that <i class="emphasis">v</i>(<i class="emphasis">k</i>) is assumed to be zero mean. Using this fact together with the linearity property of the <a name="706"></a><a name="page279"></a>expectation yields</p>
<div class="informalequation" mathml="yes">
<img src="figu279_1.jpg" /><br />
</div>
<p class="para">The first expectation term in this equation matches the definition of the covariance matrix <i class="emphasis">P</i>(<i class="emphasis">k</i> | <i class="emphasis">k</i>), while the second expectation term matches the definition of the covariance matrix <i class="emphasis">V</i>(<i class="emphasis">k</i>). As a result we can write the prediction equation</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.12) </span></td><td valign="top"><img src="figu279_2.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">To perform the update step, we choose <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1117" src="figu279_3.jpg" height="16" width="116" title="" border="0" /></span></span> to be the most likely point <i class="emphasis">x</i> in the set</p>
<div class="informalequation" mathml="yes">
<img src="figu279_4.jpg" /><br />
</div>
<p class="para">Hence, we look for <i class="emphasis">x</i> <span class="unicode">&#8714;</span> <span class="unicode">&#937;</span> that maximizes the Gaussian distribution defined by <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1119" src="figu279_5.jpg" height="18" width="98" title="" border="0" /></span></span> and <i class="emphasis">P</i>(<i class="emphasis">k</i> + 1 | <i class="emphasis">k</i>), i.e.,</p>
<div class="informalequation" mathml="yes">
<img src="figu279_6.jpg" /><br />
</div>
<p class="para">Because the exponential is monotonically increasing, <i class="emphasis">p</i>(<i class="emphasis">x</i>) is maximized when <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1121" src="figu279_7.jpg" height="19" width="400" title="" border="0" /></span></span> is minimized. With this in mind, we introduce a new notion of distance with the norm<sup>[<a name="ch08fnt08_5" href="#ftn.ch08fnt08_5">5</a>]</sup>
</p>
<div class="informalequation" mathml="yes">
<img src="figu279_8.jpg" /><br />
</div>
<p class="para">which is derived from the new inner product on <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1126" src="figu279_9.jpg" height="15" width="22" title="" border="0" /></span></span>,</p>
<div class="informalequation" mathml="yes">
<img src="figu279_10.jpg" /><br />
</div>
<p class="para">Define <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1128" src="figu279_11.jpg" height="18" width="321" title="" border="0" /></span></span>. So we want to find <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1129" src="figu279_12.jpg" height="18" width="139" title="" border="0" /></span></span> such that</p>
<ol class="orderedlist">
<li class="first-listitem">
<p class="first-para">||<span class="unicode">&#916;</span><i class="emphasis">x</i>||<sub><i class="emphasis">M</i></sub> is minimized.</p>
</li>
<li class="listitem">
<p class="first-para">
<span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1130" src="figu279_13.jpg" height="19" width="214" title="" border="0" /></span></span>.</p>
</li>
</ol>
<p class="para">The first condition means that the vector <span class="unicode">&#916;</span><i class="emphasis">x</i> is orthogonal to the hyperplane <span class="unicode">&#937;</span> with respect to the inner product <span class="unicode">&#12296;</span>·, ·<span class="unicode">&#12297;</span><sub><i class="emphasis">M</i></sub>. This notion is depicted graphically in <a class="internaljump" href="#ch08fig03">figure 8.3</a>. The ellipses in this figure represent sets of points that are equidistant to <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1131" src="figu279_14.jpg" height="18" width="99" title="" border="0" /></span></span> according to the ||·||<sub><i class="emphasis">M</i></sub> norm. With this notion of distance, choosing <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1132" src="figu279_15.jpg" height="18" width="134" title="" border="0" /></span></span> to be the closest point on <span class="unicode">&#937;</span> to <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1133" src="figu279_16.jpg" height="18" width="94" title="" border="0" /></span></span> is equivalent to choosing the point at which <a name="708"></a><a name="IDX-280"></a>one of the equidistant ellipses tangentially intersects <span class="unicode">&#937;</span>. The resulting <span class="unicode">&#916;</span><i class="emphasis">x</i> must be orthogonal to <span class="unicode">&#937;</span>, but our notion of orthogonality is skewed by <i class="emphasis">P</i>(<i class="emphasis">k</i> + 1 | <i class="emphasis">k</i>)<sup>&#8722;1</sup>. This means that we must have</p>
<div class="informalequation" mathml="yes">
<img src="figu280_1.jpg" /><br />
</div>
<div class="figure">
<a name="709"></a><a name="ch08fig03"></a><span class="figuremediaobject"><a href="javascript:PopImage('IMG_1135','fig8-3_0.jpg','973','776')" name="IMG_1135" target="_self"><img alt="Image from book" id="IMG_1135" src="fig8-3.jpg" height="279" width="350" title="Click To expand" border="0" /></a></span>
<br style="line-height: 1" />
<span class="figure-title"><span class="figure-titlelabel">Figure 8.3: </span>Correction determines the "closest" and "most likely" state on the set of states <span class="unicode">&#937;</span>.</span>
</div>
<p class="para">for all <i class="emphasis">a</i> <span class="unicode">&#8714;</span> null(<i class="emphasis">H</i>(<i class="emphasis">k</i> + 1)). In the remainder of this section, we simply denote <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1) by <i class="emphasis">H</i> for brevity. Using the linear algebra facts presented earlier, this expression can only be true if <span class="unicode">&#916;</span><i class="emphasis">x</i> <span class="unicode">&#8714;</span> column(<i class="emphasis">P</i>(<i class="emphasis">k</i> + 1 | <i class="emphasis">k</i>)<i class="emphasis">H<sup>T</sup></i>), which means that</p>
<div class="informalequation" mathml="yes">
<img src="figu280_2.jpg" /><br />
</div>
<p class="para">for some <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1137" src="figu280_3.jpg" height="19" width="67" title="" border="0" /></span></span>. As in the case of the simple observer, we guess that <span class="unicode">&#947;</span> can be expressed as a linear function of the innovation error <span class="unicode">&#957;</span> = <i class="emphasis">y</i>(<i class="emphasis">k</i> + 1) <span class="unicode">&#8722;</span> <i class="emphasis">Hx</i>(<i class="emphasis">k</i> + 1 | <i class="emphasis">k</i>), i.e.,</p>
<div class="equation" mathml="yes">
<a name="710"></a><a name="ch08eqn13"></a>
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.13) </span></td><td valign="top"><img src="figu280_4.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">for some <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1139" src="figu280_5.jpg" height="15" width="87" title="" border="0" /></span></span>. Now we enforce <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1140" src="figu280_6.jpg" height="16" width="180" title="" border="0" /></span></span>, i.e.,</p>
<div class="informalequation" mathml="yes">
<img src="figu280_7.jpg" /><br />
</div>
<p class="para">which implies that <i class="emphasis">H</i> <span class="unicode">&#916;</span><i class="emphasis">x</i> = <span class="unicode">&#957;</span>. Substituting for <span class="unicode">&#916;</span><i class="emphasis">x</i> from <a class="internaljump" href="#ch08eqn13">equation (8.13)</a> yields</p>
<div class="informalequation" mathml="yes">
<img src="figu280_8.jpg" /><br />
</div>
<p class="para">
<a name="711"></a><a name="IDX-281"></a>which means that we must have</p>
<div class="informalequation" mathml="yes">
<img src="figu281_1.jpg" /><br />
</div>
<p class="para">The resulting update equation for the state vector estimate is</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.14) </span></td><td valign="top"><img src="figu281_2.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">To ease notation, we define</p>
<div class="informalequation" mathml="yes">
<img src="figu281_3.jpg" /><br />
</div>
<p class="para">so that the update equation can be written simply</p>
<div class="informalequation" mathml="yes">
<img src="figu281_4.jpg" /><br />
</div>
<p class="para">To find the update equation for the covariance matrix estimate, we use the definition of the covariance matrix together with the update equation for the state vector estimate to get</p>
<div class="equation" mathml="yes">
<a name="712"></a><a name="ch08eqn15"></a>
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.15) </span></td><td valign="top"><img src="figu281_5.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">The details of this derivation are the subject of problem 7.</p>
<p class="para">Summarizing the observer derived in this section:</p>
<p class="para">
<b class="bold"><i class="emphasis">prediction:</i></b>
</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.16) </span></td><td valign="top"><img src="figu281_6.jpg" /><br /></td>
</tr>
</table>
</div>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.17) </span></td><td valign="top"><img src="figu281_7.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">
<b class="bold"><i class="emphasis">update:</i></b>
</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.18) </span></td><td valign="top"><img src="figu281_8.jpg" /><br /></td>
</tr>
</table>
</div>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.19) </span></td><td valign="top"><img src="figu281_9.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">where</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.20) </span></td><td valign="top"><img src="figu281_10.jpg" /><br /></td>
</tr>
</table>
</div>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.21) </span></td><td valign="top"><img src="figu281_11.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">and <i class="emphasis">H</i> is shorthand for <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1).</p>
<p class="last-para">As in the case of the simple observer, this observer also has some problems. Because we assumed no sensor noise, the update equations will cause the covariance matrix estimate to become singular. This makes sense: noiseless measurements mean that the uncertainty in the directions associated with the sensor measurements will be zero. But the singular covariance makes the resulting notions of Gaussian distribution and Mahalanobis distance meaningless since they rely on the inverse of <i class="emphasis">P</i>. Still, the intuition behind using and propagating a Gaussian distribution as a state estimate is in line <a name="713"></a><a name="IDX-282"></a>with the intuition behind the Kalman filter in spite of this problem. In the <a class="internaljump" href="#ch08lev2sec4">next section</a>, we advance this intuition one final step to derive the full Kalman filter equations.</p>
</div>
<div class="section">
<h3 class="sect3-title">
<a name="714"></a><a name="ch08lev2sec4"></a><span class="section-titlelabel">8.2.4 </span>The Kalman Filter</h3>
<p class="first-para">Consider the system described at the beginning of this chapter:</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.22) </span></td><td valign="top"><img src="figu282_1.jpg" /><br /></td>
</tr>
</table>
</div>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.23) </span></td><td valign="top"><img src="figu282_2.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">The only difference between this system and the system in the <a class="internaljump" href="#ch08lev2sec3">previous section</a> is that we have included the sensor noise term <i class="emphasis">w</i>(<i class="emphasis">k</i>), a zero-mean white Gaussian random vector with covariance matrix <i class="emphasis">W</i>(<i class="emphasis">k</i>).</p>
<p class="para">Since the dynamic equation has not changed, the prediction step for the Kalman filter is identical to the prediction step for the observer defined in <a class="internaljump" href="#ch08lev2sec3">section 8.2.3</a>. The addition of noise to the sensor equation significantly changes the update step, however. In the previous case, the output <i class="emphasis">y</i>(<i class="emphasis">k</i> + 1) constrained the next estimate <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1156" src="figu282_3.jpg" height="18" width="126" title="" border="0" /></span></span> to lie in the hyperplane <span class="unicode">&#937;</span>. We knew exactly what the output <i class="emphasis">y</i>(<i class="emphasis">k</i> + 1) had to be, and we chose <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1157" src="figu282_4.jpg" height="18" width="129" title="" border="0" /></span></span> to match it. As a result, we could use the algebraic equation <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1158" src="figu282_5.jpg" height="19" width="324" title="" border="0" /></span></span> to find <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1159" src="figu282_6.jpg" height="19" width="137" title="" border="0" /></span></span>. In the current case, there is no such algebraic constraint. We do not know exactly what the output should be; we only know that it is drawn from a Gaussian distribution in <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1160" src="figu282_7.jpg" height="15" width="23" title="" border="0" /></span></span> with mean <i class="emphasis">y</i>(<i class="emphasis">k</i> + 1) and covariance matrix <i class="emphasis">W</i>(<i class="emphasis">k</i>). Without this constraint, we cannot use the same algebraic approach to define <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1161" src="figu282_8.jpg" height="19" width="141" title="" border="0" /></span></span>. Instead, we will first look for the most likely output <i class="emphasis">y</i>* given the prediction <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1162" src="figu282_9.jpg" height="19" width="228" title="" border="0" /></span></span> together with the measured output <i class="emphasis">y</i>(<i class="emphasis">k</i> + 1). Once we have <i class="emphasis">y</i>*, we can introduce the algebraic constraint <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1163" src="figu282_10.jpg" height="19" width="269" title="" border="0" /></span></span> and proceed as before.</p>
<p class="para">We begin to find <i class="emphasis">y</i>* by projecting the prediction into output space. Using the output map <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1) and the definition of covariance, we see that the state space distribution with mean <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1164" src="figu282_11.jpg" height="18" width="99" title="" border="0" /></span></span> and covariance matrix <i class="emphasis">P</i>(<i class="emphasis">k</i> + 1 | <i class="emphasis">k</i>) projects into a Gaussian distribution in the output space <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1165" src="figu282_12.jpg" height="18" width="37" title="" border="0" /></span></span> with mean</p>
<div class="informalequation" mathml="yes">
<img src="figu282_13.jpg" /><br />
</div>
<p class="para">and covariance matrix</p>
<div class="informalequation" mathml="yes">
<img src="figu282_14.jpg" /><br />
</div>
<p class="para">
<a name="715"></a><a name="page283"></a>The most likely output <i class="emphasis">y</i>* is then defined to be the most likely point in the output space <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1168" src="figu283_1.jpg" height="15" width="24" title="" border="0" /></span></span> given the Gaussian distribution that results from projecting the prediction and the Gaussian distribution that results from taking the measurement. The projected prediction and output distributions have mean-covariance pairs <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1169" src="figu283_2.jpg" height="25" width="56" title="" border="0" /></span></span> and (<i class="emphasis">y</i>(<i class="emphasis">k</i> + 1), <i class="emphasis">W</i> (<i class="emphasis">k</i> + 1)), respectively. Since these distributions are independent, <i class="emphasis">y</i>* will be the peak of the function that results from taking their product. Fortunately the product of two Gaussian distributions is also Gaussian and the result can be obtained using a wellknown formula [389]. We summarize the required result as a theorem:</p>
<div class="example">
<span class="example-title"><span class="example-titlelabel">THEOREM 8.2.1: </span>(Product of Gaussians)</span><a name="716"></a><a name="ch08th02_1"></a>
<div class="formalbody">
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img alt="Image from book" src="_.gif" width="1" height="2" title="Start example" border="0" /></b></font></td>
</tr>
</table>
<p class="first-para">The product of two Gaussian distributions with mean-covariance pairs (<i class="emphasis">z</i><sub>1</sub>, <i class="emphasis">C</i><sub>1</sub>) and (<i class="emphasis">z</i><sub>2</sub>, <i class="emphasis">C</i><sub>2</sub>) is proportional to a third Gaussian with mean vector</p>
<div class="informalequation" mathml="yes">
<img src="figu283_3.jpg" /><br />
</div>
<p class="para">and covariance matrix</p>
<div class="informalequation" mathml="yes">
<img src="figu283_4.jpg" /><br />
</div>
<p class="para">where</p>
<div class="informalequation" mathml="yes">
<img src="figu283_5.jpg" /><br />
</div>
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img alt="Image from book" src="_.gif" width="1" height="2" title="End example" border="0" /></b></font></td>
</tr>
</table>
<table class="BlankSpace" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td height="16"></td>
</tr>
</table>
</div>
</div>
<p class="para">To sketch the proof of this theorem, we use the property that the product of two exponentials is the exponential of the sum of the exponents. A clever reordering of the terms in the resulting sum yields the result. See problem 8 for the details of the proof.</p>
<p class="para">Applying <a class="internaljump" href="#ch08th02_1">theorem 8.2.1</a>,</p>
<div class="informalequation" mathml="yes">
<img src="figu283_6.jpg" /><br />
</div>
<p class="para">Now that we have found the most likely output <i class="emphasis">y</i>*, we can define <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1174" src="figu283_7.jpg" height="21" width="284" title="" border="0" /></span></span> and, as in the <a class="internaljump" href="#ch08lev2sec3">previous section</a>, proceed to find the <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1175" src="figu283_8.jpg" height="18" width="298" title="" border="0" /></span></span> that minimizes ||<span class="unicode">&#916;</span><i class="emphasis">x</i>||<sub><i class="emphasis">M</i></sub> while satisfying <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1176" src="figu283_9.jpg" height="16" width="152" title="" border="0" /></span></span> (see <a class="internaljump" href="#ch08fig04">figure 8.4</a>). Using <i class="emphasis">H</i> to denote <i class="emphasis">H</i>(<i class="emphasis">k</i> + 1), we get the result</p>
<div class="informalequation" mathml="yes">
<img src="figu283_10.jpg" /><br />
</div>
<p class="para">where, as before, <span class="unicode">&#957;</span> = <i class="emphasis">y</i>(<i class="emphasis">k</i> + 1) <span class="unicode">&#8722;</span> <i class="emphasis">Hx</i>(<i class="emphasis">k</i> + 1 | <i class="emphasis">k</i>) is the innovation error. Defining</p>
<div class="informalequation" mathml="yes">
<img src="figu283_11.jpg" /><br />
</div>
<p class="para">we can write the state vector estimate update equation</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.24) </span></td><td valign="top"><img src="figu283_12.jpg" /><br /></td>
</tr>
</table>
</div>
<div class="figure">
<a name="717"></a><a name="ch08fig04"></a><span class="figuremediaobject"><a href="javascript:PopImage('IMG_1181','fig8-4_0.jpg','910','866')" name="IMG_1181" target="_self"><img alt="Image from book" id="IMG_1181" src="fig8-4.jpg" height="333" width="350" title="Click To expand" border="0" /></a></span>
<br style="line-height: 1" />
<span class="figure-title"><span class="figure-titlelabel">Figure 8.4: </span>The sensor noise distribution is projected into the state space and is an extruded Gaussian centered on the states consistent with the current sensor reading. The most likely output <i class="emphasis">y</i>* is determined by multiplying the Gaussian distribution that results from the measurement <i class="emphasis">y</i>(<i class="emphasis">k</i> + 1) with the Gaussian distribution that results from projecting the prediction into the output space. This then corresponds to a set of states <span class="unicode">&#937;</span>*. The update is the point on <span class="unicode">&#937;</span>* that is closest to the prediction <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1180" src="figu284_1.jpg" height="16" width="89" title="" border="0" /></span></span> in the sense of Mahalanobis distance.</span>
</div>
<p class="para">
<a name="718"></a><a name="page284"></a>To find the update equation for the covariance matrix estimate, we use the definition of the covariance matrix together with the update equation for the state vector estimate to get</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.25) </span></td><td valign="top"><img src="figu284_2.jpg" /><br /></td>
</tr>
</table>
</div>
</div>
<div class="section">
<h3 class="sect3-title">
<a name="719"></a><a name="ch08lev2sec5"></a><span class="section-titlelabel">8.2.5 </span>Kalman Filter Summary</h3>
<p class="first-para">The Kalman filter equations are summarized as follows:</p>
<p class="para">
<b class="bold"><i class="emphasis">prediction:</i></b>
</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.26) </span></td><td valign="top"><img src="figu284_3.jpg" /><br /></td>
</tr>
</table>
</div>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.27) </span></td><td valign="top"><img src="figu284_4.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">
<a name="720"></a><a name="page285"></a><b class="bold"><i class="emphasis">update:</i></b>
</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.28) </span></td><td valign="top"><img src="figu285_1.jpg" /><br /></td>
</tr>
</table>
</div>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.29) </span></td><td valign="top"><img src="figu285_2.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">where</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.30) </span></td><td valign="top"><img src="figu285_3.jpg" /><br /></td>
</tr>
</table>
</div>
<div class="equation" mathml="yes">
<a name="721"></a><a name="ch08eqn31"></a>
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.31) </span></td><td valign="top"><img src="figu285_4.jpg" /><br /></td>
</tr>
</table>
</div>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.32) </span></td><td valign="top"><img src="figu285_5.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">These equations provide the optimal estimate of <i class="emphasis">x</i> in the sense that the expected value of the error between <i class="emphasis">x</i>(<i class="emphasis">k</i>) and <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1190" src="figu285_6.jpg" height="18" width="59" title="" border="0" /></span></span> is minimized at every <i class="emphasis">k</i>. One can view <i class="emphasis">R</i> as the weighting factor that takes into account the relationship between the accuracy of the predicted estimate and the measurement noise. If <i class="emphasis">R</i> is "large," then the sensor readings are more believable than the prediction and the Kalman filter weights the sensor reading highly when computing the updated estimate. If <i class="emphasis">R</i> is "small," then the sensor readings are not as believable and, as a result, they do not have as much influnce in the update step.</p>
<p class="para">In this chapter we have chosen to present the derivation of the Kalman filter equations as an optimization problem because we believe that to be an intuitive approach. It is important to note, however, that the state and covariance estimates that result from the use of these equations are not only the "best" estimates, they are also the "correct" estimates. If the estimate at time <i class="emphasis">k</i> is Gaussian and described by <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1191" src="figu285_7.jpg" height="19" width="149" title="" border="0" /></span></span>, then the correct distribution at time <i class="emphasis">k</i> + 1 (i.e., the <i class="emphasis">posterior</i> distribution) is in fact also Gaussian and is described by <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1192" src="figu285_8.jpg" height="19" width="307" title="" border="0" /></span></span>.</p>
<p class="last-para">If we allow the noise terms <i class="emphasis">v</i>(<i class="emphasis">k</i>) and <i class="emphasis">w</i>(<i class="emphasis">k</i>) to have non-Gaussian distributions, then these equations still provide the best <i class="emphasis">linear</i> estimator, but there may be nonlinear estimators that do a better job.</p>
</div>
<div class="section">
<h3 class="sect3-title">
<a name="722"></a><a name="ch08lev2sec6"></a><span class="section-titlelabel">8.2.6 </span>Example: Kalman Filter for Dead Reckoning</h3>
<p class="first-para">In mobile robotics, the term <i class="emphasis">dead reckoning</i> typically refers to a position estimate achieved by integrating odometry measurements. Here we present an example of a more sophisticated form of dead reckoning where a Kalman filter is used to fuse the robot commands (inputs) with measurements from odometry sensors.</p>
<p class="para">Consider a mobile robot constrained to move along a straight line. The robot state is defined to be <i class="emphasis">x</i> = [<i class="emphasis">x<sub>r</sub></i>, <i class="emphasis">v<sub>r</sub></i>]<sup><i class="emphasis">T</i></sup> where <i class="emphasis">x<sub>r</sub></i> and <i class="emphasis">v<sub>r</sub></i> are the robot position and velocity, respectively. The input <i class="emphasis">u</i> is a real-valued force applied to the robot. Newton's law states that <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1193" src="figu285_9.jpg" height="26" width="66" title="" border="0" /></span></span>, where <i class="emphasis">m</i> is the mass of the robot. This can be approximated by <a name="723"></a><a name="IDX-286"></a>the discrete time equation</p>
<div class="informalequation" mathml="yes">
<img src="figu286_1.jpg" /><br />
</div>
<p class="para">where <i class="emphasis">T</i> is the sampling rate (in seconds) of the discretization. So then the discrete time state equation can be written as</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.33) </span></td><td valign="top"><img src="figu286_2.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">where the process noise term <i class="emphasis">v</i>(<i class="emphasis">k</i>) is used to account for errors that arise from unmodeled sources such as discretization and friction. The vector <i class="emphasis">v</i>(<i class="emphasis">k</i>) is assumed to be zero-mean white Gaussian noise with covariance matrix <i class="emphasis">V</i>.</p>
<p class="para">We assume that the robot is equipped with a sensor that measures velocity. We also assume that the error in this measurement is well modeled as zero-mean white Gaussian noise with known variance <i class="emphasis">W</i>. Then the output <i class="emphasis">y</i>(<i class="emphasis">k</i>) can be written</p>
<div class="equation" mathml="yes">
<table border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top"><span class="equation-label">(8.34) </span></td><td valign="top"><img src="figu286_3.jpg" /><br /></td>
</tr>
</table>
</div>
<p class="para">where <i class="emphasis">w</i> is the noise term.</p>
<p class="para">Now the Kalman filter can be applied using the sequence of equations listed in <a class="internaljump" href="#ch08lev2sec5">section 8.2.5</a>. We simulated this example in MATLAB using the parameters <i class="emphasis">m</i> = 1, <i class="emphasis">W</i> = .5, <i class="emphasis">T</i> = 0.5, and</p>
<div class="informalequation" mathml="yes">
<img src="figu286_4.jpg" /><br />
</div>
<p class="para">Assume that the input at time <i class="emphasis">k</i> is known to be <i class="emphasis">u</i>(<i class="emphasis">k</i>) = 0, and assume an initial state estimate of <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1198" src="figu286_5.jpg" height="21" width="150" title="" border="0" /></span></span> and an initial covariance estimate of</p>
<div class="informalequation" mathml="yes">
<img src="figu286_6.jpg" /><br />
</div>
<p class="para">Further, assume that the (unknown) value of the actual state is <i class="emphasis">x</i>(<i class="emphasis">k</i> + 1) = [1.8, 2]<sup><i class="emphasis">T</i></sup>. The sequence of prediction, combining prediction with measurement in output space, and update are depicted graphically in <a class="internaljump" href="#ch08fig05">figures 8.5</a>, <a class="internaljump" href="#ch08fig06">8.6</a>, and <a class="internaljump" href="#ch08fig07">8.7</a>. Here, the two-dimensional Gaussian distributions that result from <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1200" src="figu286_7.jpg" height="15" width="10" title="" border="0" /></span></span> and <i class="emphasis">P</i> are represented by confidence ellipses. Specifically, these ellipses are chosen so that the probability that the actual value of the state <i class="emphasis">x</i> is contained within the ellipse is 0.95.</p>
<div class="figure">
<a name="724"></a><a name="ch08fig05"></a><span class="figuremediaobject"><a href="javascript:PopImage('IMG_1202','fig8-5_0.jpg','919','792')" name="IMG_1202" target="_self"><img alt="Image from book" id="IMG_1202" src="fig8-5.jpg" height="302" width="350" title="Click To expand" border="0" /></a></span>
<br style="line-height: 1" />
<span class="figure-title"><span class="figure-titlelabel">Figure 8.5: </span>The initial estimate <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1201" src="figu287_1.jpg" height="16" width="54" title="" border="0" /></span></span> has an uncertainty <i class="emphasis">P</i>(<i class="emphasis">k</i> | <i class="emphasis">k</i>) which grows to <i class="emphasis">P</i>(<i class="emphasis">k</i> + 1 | <i class="emphasis">k</i>) when the robot moves, reflecting the increase in uncertainty. This increase in uncertainty is depicted by plotting the 0.95 confidence ellipses.</span>
</div>
<div class="figure">
<a name="725"></a><a name="ch08fig06"></a><span class="figuremediaobject"><a href="javascript:PopImage('IMG_1203','fig8-6_0.jpg','1000','837')" name="IMG_1203" target="_self"><img alt="Image from book" id="IMG_1203" src="fig8-6.jpg" height="293" width="350" title="Click To expand" border="0" /></a></span>
<br style="line-height: 1" />
<span class="figure-title"><span class="figure-titlelabel">Figure 8.6: </span>Measurements and predictions are then merged. The PDF plotted with the dot-dashed line results from the combination of the measurement PDF and the PDF of the prediction projected into output space, where the combination is computed using <a class="internaljump" href="#ch08th02_1">theorem 8.2.1</a>. The most likely output <i class="emphasis">y</i>* is the value at which this combined distribution reaches its peak.</span>
</div>
<div class="figure">
<a name="726"></a><a name="ch08fig07"></a><span class="figuremediaobject"><a href="javascript:PopImage('IMG_1207','fig8-7_0.jpg','1000','857')" name="IMG_1207" target="_self"><img alt="Image from book" id="IMG_1207" src="fig8-7.jpg" height="300" width="350" title="Click To expand" border="0" /></a></span>
<br style="line-height: 1" />
<span class="figure-title"><span class="figure-titlelabel">Figure 8.7: </span>The updated estimate <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1204" src="figu289_1.jpg" height="16" width="109" title="" border="0" /></span></span> is the point on <span class="unicode">&#937;</span>* that is closest to <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1205" src="figu289_2.jpg" height="16" width="81" title="" border="0" /></span></span> in terms of Mahalanobis distance. The smaller of the two dotted ellipses is the smallest ellipse that intersects <span class="unicode">&#937;</span>*, hence <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1206" src="figu289_3.jpg" height="16" width="123" title="" border="0" /></span></span> is defined by this intersection. Note that the line <span class="unicode">&#937;</span>* represents the set of states that are consistent with the most likely output <i class="emphasis">y</i>* that was found in <a class="internaljump" href="#ch08fig06">figure 8.6</a>.</span>
</div>
</div>
<div class="section">
<h3 class="sect3-title">
<a name="727"></a><a name="ch08lev2sec7"></a><span class="section-titlelabel">8.2.7 </span>Observability in Linear Systems</h3>
<p class="first-para">
<a name="728"></a><a name="page287"></a>Note that in the update step of the previous example, the updated ellipse is "squished" significantly in the vertical direction. This squishing corresponds to the information gained from the velocity measurement. For this particular example, each iteration of the Kalman filter will reflect a gain of information in the velocity direction and a loss of information in the position direction. As a result, the expected error on the position estimate will grow monotonically without bound. This failure is not the fault of the Kalman filter, which is guaranteed to provide the best possible estimate. The problem instead lies with the system itself; specifically, the system dynamics and output equations do not interact in a way that allows the state to be recovered from the available outputs. In other words, the system in the example fails to be observable.</p>
<p class="para">Loosely speaking, a system is said to be <i class="emphasis">observable</i> if the full state can be reconstructed by observing the input <i class="emphasis">u</i> and the output <i class="emphasis">y</i> over some period of time (see <a href="102.html" class="chapterjump">appendix J</a> for a discussion of observability in linear systems.) For linear systems where the system matrices <i class="emphasis">F</i>(<i class="emphasis">k</i>) and <i class="emphasis">H</i>(<i class="emphasis">k</i>) do not vary with <i class="emphasis">k</i>, there is a simple test to determine observability:</p>
<div class="example">
<span class="example-title"><span class="example-titlelabel">THEOREM 8.2.2: </span>(Observability Test)</span><a name="729"></a><a name="ch08th02_2"></a>
<div class="formalbody">
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img alt="Image from book" src="_.gif" width="1" height="2" title="Start example" border="0" /></b></font></td>
</tr>
</table>
<p class="first-para">
<a name="730"></a><a name="IDX-288"></a>The linear time-invariant discrete time system</p>
<div class="informalequation" mathml="yes">
<img src="figu288_1.jpg" /><br />
</div>
<p class="para">is observable if and only if the observability matrix</p>
<div class="informalequation" mathml="yes">
<img src="figu288_2.jpg" /><br />
</div>
<p class="last-para">has rank n.</p>
<table class="BlueLine" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td bgcolor="000080" class="bluecell"><font size="2" face="Arial" color="010100"><b><img alt="Image from book" src="_.gif" width="1" height="2" title="End example" border="0" /></b></font></td>
</tr>
</table>
<table class="BlankSpace" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td height="16"></td>
</tr>
</table>
</div>
</div>
<p class="last-para">
<a name="731"></a><a name="page289"></a>For any observable linear system, the estimate provided by the Kalman filter is guaranteed to converge in the sense that the expected error between the actual and estimated state will be bounded for all time.</p>
</div>
</div>
<div class="footnotes">
<div class="footnote">
<p>
<a name="689"></a><sup>[<a name="ftn.ch08fnt08_1" href="#ch08fnt08_1">1</a>]</sup>Here the term "white" means that the vector <i class="emphasis">v</i>(<i class="emphasis">k</i>) is independent of <i class="emphasis">v</i>(<i class="emphasis">k</i> <span class="unicode">&#8722;</span> 1) for all <i class="emphasis">k</i>. The properties of a Gaussian distribution, which is defined entirely by its mean vector and covariance matrix, is discussed in more detail later in this chapter.</p>
</div>
<div class="footnote">
<p>
<a name="691"></a><sup>[<a name="ftn.ch08fnt08_2" href="#ch08fnt08_2">2</a>]</sup>For this to be possible the pair (<i class="emphasis">F</i>, <i class="emphasis">H</i>) must be observable, a property which is discussed briefly in <a class="internaljump" href="#ch08lev2sec7">section 8.2.7</a>. Observability is also discussed in the overview of linear time invariant control systems in <a href="102.html" class="chapterjump">appendix J</a>. A more thorough discussion can be found in any good linear systems theory textbook, e.g., [214].</p>
</div>
<div class="footnote">
<p>
<a name="694"></a><sup>[<a name="ftn.ch08fnt08_3" href="#ch08fnt08_3">3</a>]</sup>Note that the definition of <i class="emphasis">recursive</i> is subtly different from what is commonly found in computer science.</p>
</div>
<div class="footnote">
<p>
<a name="698"></a><sup>[<a name="ftn.ch08fnt08_4" href="#ch08fnt08_4">4</a>]</sup>Technically, we must also define what we mean by "parallel." We say a vector <i class="emphasis">a</i> is <i class="emphasis">parallel</i> to a hyperplane <span class="unicode">&#937;</span> if <i class="emphasis">x</i> + <i class="emphasis">a</i> <span class="unicode">&#8714;</span> for every <i class="emphasis">x</i> <span class="unicode">&#8714;</span> <span class="unicode">&#937;</span>.</p>
</div>
<div class="footnote">
<p>
<a name="707"></a><sup>[<a name="ftn.ch08fnt08_5" href="#ch08fnt08_5">5</a>]</sup><span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1122" src="figu279_17.jpg" height="14" width="148" title="" border="0" /></span></span> is called the <i class="citetitle">Mahalanobis distance</i> between <i class="emphasis">x</i> and <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1123" src="figu279_18.jpg" height="11" width="8" title="" border="0" /></span></span>. The Mahalanobis distance indicates how far away the point <i class="emphasis">x</i> is from the mean <span class="inlinequation" xmlns:mml="http://www.w3.org/1998/Math/MathML"><span class="inlinemediaobject"><img alt="Image from book" id="IMG_1124" src="figu279_19.jpg" height="12" width="8" title="" border="0" /></span></span> in units of standard deviations.</p>
</div>
</div>
</div><table border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td colspan="3" height="5"><img src="images/_.gif" width="1" alt="" border="0" height="5" /></td>
</tr>
<tr>
<td class="b24-chunknavigate" width="25%" align="left"><a border="0" accesskey="P" href="49.html"><img src="images/arrow_readprevious.gif" width="94" height="22" hspace="0" alt="Previous Section" title="Previous Section" border="0" /></a></td>
<td class="b24-chunknavigate" width="75%" align="center">
<table cellpadding="0" cellspacing="0" border="0">
</table>
</td>
<td class="b24-chunknavigate" width="25%" align="right"><a border="0" href="viewer.asp?bookid=10749&amp;chunkid=671608266"><img width="1" height="1" hspace="1" border="0" alt="" src="images/_.gif" /></a><a border="0" accesskey="N" href="51.html"><img src="images/arrow_readnext.gif" width="94" height="22" hspace="0" alt="Next Section" title="Next Section" border="0" /></a></td>
</tr>
<tr>
<td colspan="3" height="5"><img src="images/_.gif" width="1" alt="" border="0" height="5" /></td>
</tr>
</table>
<table border="0" cellspacing="0" cellpadding="0" width="100%" bgcolor="#FFFFFF" height="50">
<tr><td bgcolor="#000000"><img src="images/_.gif" width="1" height="1" alt="" border="0" /></td></tr>
<tr><td><?xml version='1.0' encoding='utf-8'?><table border="0" width="100%" cellspacing="0" cellpadding="0"><tr><td width="99%" valign="Top" class="footer"><b>TeamUnknown Release</b></td></tr></table></td></tr>
<div id="download" class="b24-download_bubble"></div>
</table></body>
</html>
